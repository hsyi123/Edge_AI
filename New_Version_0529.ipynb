{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-zIwy78cbvl_dmqKH3c2XhN2BIJ7tcsR","timestamp":1685371881178},{"file_id":"1VTYxd5NdNh8htpS7IjFgGXl9VtH6OxoP","timestamp":1685075067742}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8Q1no4FT0QfI"},"source":["#2021繁體中文場景文字辨識比賽 - 單字辨識範例\n","這個Colab Notebook的目的是給你一個「中文單字辨識」的簡易範例，將會帶著你從資料的生成，到訓練的撰寫。\n","\n","今天你如果想要創造一個 人工智慧機器，你希望從一張街景照片上截下一個中文單字，我們就假定是拿坡里中的「拿」好了 ![拿坡里](https://drive.google.com/uc?export=view&id=1oaP4lY7EKag8r0zB8sXKZ-B_DnJxt4l4)\n","\n","你希望餵給你的人工智慧機器 ![拿](https://drive.google.com/uc?export=view&id=1xAixH6gycmYe5B9RHixcX_TzbENHHCxD) 這個中文單字圖片，它能夠辨識出這個字是「拿」，你會怎麼做呢，讓我們從資料集開始～\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gbyy9fgJa0cF"},"source":["## 一、 資料集生成"]},{"cell_type":"markdown","metadata":{"id":"TBNzf69d-0A_"},"source":["做深度學習最重要的就是Data，你當然可以走到街上去拍數以千張類似「拿」這樣各式各樣的圖片，再自己標記上正確答案，但那樣的話太花費力氣了，而且不是每個字你都在路上找得到。\n","\n","所以我們這邊要用的是一個單字圖片的生成工具，你可以指定字典、字型、數量、影像轉換，去生成大量資料。\n","這個工具是 [Single_char_image_generator](https://github.com/rachellin0105/Single_char_image_generator)，更多詳細資訊可以看它的README.md。\n","\n"]},{"cell_type":"code","metadata":{"id":"i2Jrd-z5vbYw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685371644818,"user_tz":-480,"elapsed":356,"user":{"displayName":"Hsiu-Yi Ou-Yang","userId":"04762442182210927554"}},"outputId":"5281204d-2602-4541-88d4-9ddf597ab4a4"},"source":["%cd /content/\n","# 把資料生成工具 clone 下來\n","!git clone https://github.com/rachellin0105/Single_char_image_generator.git\n","%cd Single_char_image_generator\n"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","fatal: destination path 'Single_char_image_generator' already exists and is not an empty directory.\n","/content/Single_char_image_generator\n"]}]},{"cell_type":"code","metadata":{"id":"rW2-ddBrPeSw","executionInfo":{"status":"ok","timestamp":1685371645279,"user_tz":-480,"elapsed":11,"user":{"displayName":"Hsiu-Yi Ou-Yang","userId":"04762442182210927554"}}},"source":["# Single_char_image_generator/chars.txt 是字典，預設有102字，可以在上面增減字。這邊因為是示範，我們只留前10個字。\n","!head -n 40 chars.txt > temp.txt\n","!mv temp.txt chars.txt"],"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BpKkK5pey8yi","executionInfo":{"status":"ok","timestamp":1685371645279,"user_tz":-480,"elapsed":7,"user":{"displayName":"Hsiu-Yi Ou-Yang","userId":"04762442182210927554"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0sJ0KY04AmW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3d5b858-007d-467a-abda-82432a4e7f35"},"source":["\n","# 安裝它需要的套件\n","!python -m pip install -r requirements.txt\n","\n","# 用一行指令執行生成 \n","!python OCR_image_generator_single_ch.py --num_per_word=500"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.7.0.72)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (8.4.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.10)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.65.0)\n","Requirement already satisfied: fontTools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.39.3)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python->-r requirements.txt (line 1)) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.16.0)\n","/content/.caches/ceb1594269364fa1c5230afd0053bf61\n","Load font(./fonts/chinse_jian/2.ttf) supported chars(40) from cache\n","/content/.caches/a56a73c2d7a54d049026dfa482bfaac9\n","Load font(./fonts/chinse_jian/simfang.ttf) supported chars(40) from cache\n","Resume generating from step 2000\n","Start generating...\n","Saving images in directory : output\n"," 18% 7/40 [03:42<17:08, 31.16s/it]"]}]},{"cell_type":"markdown","metadata":{"id":"ODCyRylbOhay"},"source":["## 使用Pytorch 訓練ResNet-18"]},{"cell_type":"markdown","metadata":{"id":"C_LNKjDgWz-Y"},"source":["首先，import我們要使用到的packages和modules進來。\n","\n","這裡使用的套件都是Google Colab本身就已經安裝好的，無須再多安裝其他套件。\n","\n","使用 `torch.cuda.is_available()` 確定現在Cuda是否支援 (能否使用GPU運算)。\n","若沒有將此Colab開啟GPU功能，此函式會回傳False。\n"]},{"cell_type":"code","metadata":{"id":"PbI_jJeDObBS"},"source":["import torch\n","from torchvision import datasets, transforms, models\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import os\n","from PIL import Image\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda:0')\n","  print('GPU')\n","else:\n","  device = torch.device('cpu')\n","  print('CPU')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_mpU7KOi2PU"},"source":["自訂一個屬於自己的資料集，繼承pytorch中的Dataset Class。\n","\n","實作 `__init__`、`__len__`、`__getitem__`三個函式"]},{"cell_type":"code","metadata":{"id":"LNcOTn9H-tzr"},"source":["class ChineseCharDataset(Dataset):\n","  def __init__(self, data_file, root_dir, dict_file):\n","    # data_file:  標註檔的路徑 (標註檔內容: ImagePath, GroundTruth)\n","    # root_dir: ImagePath所在的資料夾路徑\n","    # dict_file: 字典的路徑\n","\n","    # 使用 pandas 將生成的單字labels.txt當作csv匯入進來\n","    self.char_dataframe = pd.read_csv(data_file, index_col=False, encoding='utf-8', header=None)\n","    self.root_dir = root_dir\n","    with open(dict_file, 'r', encoding='utf-8') as f:\n","      # 將資料集包含的字集匯入進來\n","      word_list = [line for line in f.read().split('\\n') if line.strip() != '']\n","      self.dictionary = {word_list[i]: i for i in range(0, len(word_list))}\n","\n","    print(self.char_dataframe)\n","    print(self.dictionary)\n","\n","  def __len__(self):\n","    return len(self.char_dataframe)\n","\n","  def __getitem__(self, idx):\n","    \n","    # 取得第idx張圖片的path，並將圖片打開\n","    image_path = os.path.join(self.root_dir, self.char_dataframe.iloc[idx, 0])\n","    image = Image.open(image_path)\n","    \n","    # 取得 Ground Truth 並轉換成數字\n","    char = self.char_dataframe.iloc[idx, 1]\n","    char_num = self.dictionary[char]\n","\n","    \n","    return (transforms.ToTensor()(image), torch.Tensor([char_num]))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8eipU7i-wdB"},"source":["%cd /content/\n","\n","# 宣告好所有要傳入 ChineseCharDataset 的引數\n","data_file_path = './Single_char_image_generator/output/labels.txt'\n","root_dir = './Single_char_image_generator/'\n","dict_file_path = './Single_char_image_generator/chars.txt'\n","\n","# 模型儲存位置\n","save_path = './checkpoint.pt'\n","\n","# 宣告我們自訂的Dataset，把它包到 Dataloader 中以便我們訓練使用\n","char_dataset = ChineseCharDataset(data_file_path, root_dir, dict_file_path)\n","char_dataloader = DataLoader(char_dataset, batch_size=64, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZoVhIC0jndT"},"source":["__開始訓練__\n","\n","使用 ResNet-18 訓練我們的單字辨識模型"]},{"cell_type":"code","metadata":{"id":"QVs9ytX9-0X2"},"source":["# --- Training ---\n","\n","# 我們使用torchvision提供的 ResNet-18 當作我們的AI模型。 \n","net = models.resnet18(num_classes=40) # num_classes 為類別數量(幾種不一樣的字)\n","net = net.to(device) # 傳入GPU\n","net.train()\n","\n","optimizer = optim.Adam(net.parameters(), lr=0.005)\n","\n","# 訓練總共Epochs數\n","epochs = 30\n","\n","\n","each_loss = []\n","for i in tqdm(range(1, epochs + 1)):\n","  losses = 0\n","  for idx, data in enumerate(char_dataloader):\n","    image, label = data\n","    image = image.to(device)\n","    label = label.squeeze() # 將不同batch壓到同一個dimension\n","    label = label.to(device, dtype=torch.long)\n","    \n","    net.zero_grad()\n","    result = net(image)\n","\n","    # 計算損失函數\n","    loss = F.cross_entropy(result, label)\n","    losses += loss.item()\n","    if idx % 10 == 0:  # 每10個batch輸出一次\n","      print(f'epoch {i}- loss: {loss.item()}')\n","\n","    # 計算梯度，更新模型參數\n","    loss.backward()\n","    optimizer.step()\n","\n","  avgloss = losses / len(char_dataloader)\n","  each_loss.append(avgloss)\n","  print(f'{i}th epoch end. Avg loss: {avgloss}')\n","\n","# 儲存模型\n","torch.save({\n","  'epoch': epochs,\n","  'model_state_dict': net.state_dict(),\n","  'optimizer_state_dict': optimizer.state_dict(),  \n","}, save_path)\n","\n","# 畫出訓練過程圖表 (Y_axis - loss / X_axis - epoch)\n","plt.plot(each_loss, '-b', label='loss')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","# 定义计算准确率函数\n","def compute_accuracy(model, test_dataset):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_dataset:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += 1\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# 计算准确率\n","accuracy = compute_accuracy(net, char_dataloader)\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"],"metadata":{"id":"HpDKgA6q4ltX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LL5TukuP4mhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 创建一个与原始模型相同结构的模型实例\n","net = models.resnet18(num_classes=40)\n","\n","# 加载保存的权重\n","checkpoint = torch.load(save_path)\n","net.load_state_dict(checkpoint['model_state_dict'])\n","\n","# 设置模型为评估模式\n","net.eval()\n","\n","# 准备待推理的图像\n","image_path = './Single_char_image_generator/output/img_0000014.jpg'\n","image = Image.open(image_path)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","input_image = transform(image).unsqueeze(0)\n","\n","# 使用模型进行推理\n","with torch.no_grad():\n","    outputs = net(input_image)\n","\n","# 获取预测结果\n","_, predicted = torch.max(outputs, 1)\n","prediction = predicted.item()\n","\n","# 输出预测结果\n","print('Prediction:', prediction)\n"],"metadata":{"id":"dNDRx3tCy_lo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 定义类别标签映射\n","class_labels = ['肉','古','幼','酥','成','傢','婦','汎','貨','理','男','大','老','樹','民','鴻','禾','髮','酒','麗','鹽','容','由','寵','中','速','食','汽','子','院','批','洗','素','我','快','雞','出','動','品','活']  # 替换为你的实际类别标签\n","\n","# 获取预测结果\n","_, predicted = torch.max(outputs, 1)\n","prediction = predicted.item()\n","\n","# 根据类别索引获取类别标签\n","predicted_label = class_labels[prediction-1]\n","\n","image = Image.open(image_path)\n","\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()\n","# 输出预测结果\n","print('Prediction:', predicted_label)\n"],"metadata":{"id":"iDUFPBld2spc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_aoxEUFW73L-"},"execution_count":null,"outputs":[]}]}