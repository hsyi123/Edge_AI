{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsyi123/Edge_AI/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Jrd-z5vbYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1329a7b6-e959-4b0d-d12e-fb7523f9bb8d"
      },
      "source": [
        "%cd /content/\n",
        "# 把資料生成工具 clone 下來\n",
        "!git clone https://github.com/rachellin0105/Single_char_image_generator.git\n",
        "%cd Single_char_image_generator\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Single_char_image_generator'...\n",
            "remote: Enumerating objects: 508, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 508 (delta 55), reused 47 (delta 47), pack-reused 448\u001b[K\n",
            "Receiving objects: 100% (508/508), 428.80 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "/content/Single_char_image_generator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW2-ddBrPeSw"
      },
      "source": [
        "# Single_char_image_generator/chars.txt 是字典，預設有102字，可以在上面增減字。\n",
        "!head -n 40 chars.txt > temp.txt\n",
        "!mv temp.txt chars.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BpKkK5pey8yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0sJ0KY04AmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a56266b4-46ac-431a-b898-450f2fcf9f1d"
      },
      "source": [
        "\n",
        "# 安裝它需要的套件\n",
        "!python -m pip install -r requirements.txt\n",
        "\n",
        "# 用一行指令執行生成 \n",
        "!python OCR_image_generator_single_ch.py --num_per_word=500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.7.0.72)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: fontTools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.39.3)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.16.0)\n",
            "/content/.caches/a56a73c2d7a54d049026dfa482bfaac9\n",
            "Save font(./fonts/chinse_jian/simfang.ttf) supported chars(40) to cache\n",
            "/content/.caches/ceb1594269364fa1c5230afd0053bf61\n",
            "Save font(./fonts/chinse_jian/2.ttf) supported chars(40) to cache\n",
            "Start generating...\n",
            "Saving images in directory : output\n",
            " 98% 39/40 [23:23<00:35, 35.84s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODCyRylbOhay"
      },
      "source": [
        "## 使用Pytorch 訓練ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbI_jJeDObBS"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('GPU')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('CPU')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNcOTn9H-tzr"
      },
      "source": [
        "class ChineseCharDataset(Dataset):\n",
        "  def __init__(self, data_file, root_dir, dict_file):\n",
        "    # data_file:  標註檔的路徑 (標註檔內容: ImagePath, GroundTruth)\n",
        "    # root_dir: ImagePath所在的資料夾路徑\n",
        "    # dict_file: 字典的路徑\n",
        "\n",
        "    # 使用 pandas 將生成的單字labels.txt當作csv匯入進來\n",
        "    self.char_dataframe = pd.read_csv(data_file, index_col=False, encoding='utf-8', header=None)\n",
        "    self.root_dir = root_dir\n",
        "    with open(dict_file, 'r', encoding='utf-8') as f:\n",
        "      # 將資料集包含的字集匯入進來\n",
        "      word_list = [line for line in f.read().split('\\n') if line.strip() != '']\n",
        "      self.dictionary = {word_list[i]: i for i in range(0, len(word_list))}\n",
        "\n",
        "    print(self.char_dataframe)\n",
        "    print(self.dictionary)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.char_dataframe)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    # 取得第idx張圖片的path，並將圖片打開\n",
        "    image_path = os.path.join(self.root_dir, self.char_dataframe.iloc[idx, 0])\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # 取得 Ground Truth 並轉換成數字\n",
        "    char = self.char_dataframe.iloc[idx, 1]\n",
        "    char_num = self.dictionary[char]\n",
        "\n",
        "    \n",
        "    return (transforms.ToTensor()(image), torch.Tensor([char_num]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8eipU7i-wdB"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "# 宣告好所有要傳入 ChineseCharDataset 的引數\n",
        "data_file_path = './Single_char_image_generator/output/labels.txt'\n",
        "root_dir = './Single_char_image_generator/'\n",
        "dict_file_path = './Single_char_image_generator/chars.txt'\n",
        "\n",
        "# 模型儲存位置\n",
        "save_path = './checkpoint.pt'\n",
        "\n",
        "# 宣告我們自訂的Dataset，把它包到 Dataloader 中以便我們訓練使用\n",
        "char_dataset = ChineseCharDataset(data_file_path, root_dir, dict_file_path)\n",
        "char_dataloader = DataLoader(char_dataset, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVs9ytX9-0X2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4382b1-3749-499e-c4fd-d5b8d5f7fd8e"
      },
      "source": [
        "# --- Training ---\n",
        "\n",
        "# 我們使用torchvision提供的 ResNet-18 當作我們的AI模型。 \n",
        "net = models.resnet18(num_classes=40) # num_classes 為類別數量(幾種不一樣的字)\n",
        "net = net.to(device) # 傳入GPU\n",
        "net.train()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
        "\n",
        "# 訓練總共Epochs數\n",
        "epochs = 30\n",
        "\n",
        "\n",
        "each_loss = []\n",
        "for i in tqdm(range(1, epochs + 1)):\n",
        "  losses = 0\n",
        "  for idx, data in enumerate(char_dataloader):\n",
        "    image, label = data\n",
        "    image = image.to(device)\n",
        "    label = label.squeeze() # 將不同batch壓到同一個dimension\n",
        "    label = label.to(device, dtype=torch.long)\n",
        "    \n",
        "    net.zero_grad()\n",
        "    result = net(image)\n",
        "\n",
        "    # 計算損失函數\n",
        "    loss = F.cross_entropy(result, label)\n",
        "    losses += loss.item()\n",
        "    if idx % 10 == 0:  # 每10個batch輸出一次\n",
        "      print(f'epoch {i}- loss: {loss.item()}')\n",
        "\n",
        "    # 計算梯度，更新模型參數\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  avgloss = losses / len(char_dataloader)\n",
        "  each_loss.append(avgloss)\n",
        "  print(f'{i}th epoch end. Avg loss: {avgloss}')\n",
        "\n",
        "# 儲存模型\n",
        "torch.save({\n",
        "  'epoch': epochs,\n",
        "  'model_state_dict': net.state_dict(),\n",
        "  'optimizer_state_dict': optimizer.state_dict(),  \n",
        "}, save_path)\n",
        "\n",
        "# 畫出訓練過程圖表 (Y_axis - loss / X_axis - epoch)\n",
        "plt.plot(each_loss, '-b', label='loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1- loss: 3.8148410320281982\n",
            "epoch 1- loss: 4.187935829162598\n",
            "epoch 1- loss: 3.8179514408111572\n",
            "epoch 1- loss: 3.864957809448242\n",
            "epoch 1- loss: 3.7642159461975098\n",
            "epoch 1- loss: 3.7038328647613525\n",
            "epoch 1- loss: 3.7086989879608154\n",
            "epoch 1- loss: 3.4635119438171387\n",
            "epoch 1- loss: 3.31970477104187\n",
            "epoch 1- loss: 3.3028862476348877\n",
            "epoch 1- loss: 2.905038833618164\n",
            "epoch 1- loss: 2.6282732486724854\n",
            "epoch 1- loss: 1.7836042642593384\n",
            "epoch 1- loss: 1.2610650062561035\n",
            "epoch 1- loss: 1.1504255533218384\n",
            "epoch 1- loss: 1.3057258129119873\n",
            "epoch 1- loss: 1.1957378387451172\n",
            "epoch 1- loss: 1.2346185445785522\n",
            "epoch 1- loss: 1.1439452171325684\n",
            "epoch 1- loss: 1.0852470397949219\n",
            "epoch 1- loss: 1.0847910642623901\n",
            "epoch 1- loss: 1.1823923587799072\n",
            "epoch 1- loss: 1.1600979566574097\n",
            "epoch 1- loss: 1.0332534313201904\n",
            "epoch 1- loss: 0.8823889493942261\n",
            "epoch 1- loss: 1.0011093616485596\n",
            "epoch 1- loss: 0.8756234645843506\n",
            "epoch 1- loss: 0.7632589340209961\n",
            "epoch 1- loss: 0.8814308643341064\n",
            "epoch 1- loss: 0.9849485754966736\n",
            "epoch 1- loss: 0.9835830926895142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/30 [00:25<12:32, 25.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1- loss: 0.9687943458557129\n",
            "1th epoch end. Avg loss: 2.0006575736755763\n",
            "epoch 2- loss: 0.863336443901062\n",
            "epoch 2- loss: 0.9731904864311218\n",
            "epoch 2- loss: 0.9352869987487793\n",
            "epoch 2- loss: 0.8585711121559143\n",
            "epoch 2- loss: 0.8880569338798523\n",
            "epoch 2- loss: 1.0341097116470337\n",
            "epoch 2- loss: 1.075272798538208\n",
            "epoch 2- loss: 0.8755770921707153\n",
            "epoch 2- loss: 1.000191330909729\n",
            "epoch 2- loss: 0.8533651232719421\n",
            "epoch 2- loss: 0.8850147724151611\n",
            "epoch 2- loss: 0.8267309665679932\n",
            "epoch 2- loss: 1.009175419807434\n",
            "epoch 2- loss: 0.8572924733161926\n",
            "epoch 2- loss: 0.8540958762168884\n",
            "epoch 2- loss: 0.771943986415863\n",
            "epoch 2- loss: 0.966766893863678\n",
            "epoch 2- loss: 0.8897380232810974\n",
            "epoch 2- loss: 0.8211349844932556\n",
            "epoch 2- loss: 0.8137085437774658\n",
            "epoch 2- loss: 1.0870696306228638\n",
            "epoch 2- loss: 0.8907762765884399\n",
            "epoch 2- loss: 0.8384740948677063\n",
            "epoch 2- loss: 0.8597477674484253\n",
            "epoch 2- loss: 0.7410468459129333\n",
            "epoch 2- loss: 0.9192219972610474\n",
            "epoch 2- loss: 0.8509759306907654\n",
            "epoch 2- loss: 0.8858863115310669\n",
            "epoch 2- loss: 0.779776394367218\n",
            "epoch 2- loss: 0.8473612666130066\n",
            "epoch 2- loss: 0.7381255626678467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [00:38<08:31, 18.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2- loss: 0.7604695558547974\n",
            "2th epoch end. Avg loss: 0.852564136060282\n",
            "epoch 3- loss: 0.7477419972419739\n",
            "epoch 3- loss: 0.9314354658126831\n",
            "epoch 3- loss: 0.9414159059524536\n",
            "epoch 3- loss: 0.7702266573905945\n",
            "epoch 3- loss: 0.869100034236908\n",
            "epoch 3- loss: 0.7446704506874084\n",
            "epoch 3- loss: 0.74228435754776\n",
            "epoch 3- loss: 0.7387475371360779\n",
            "epoch 3- loss: 0.8270977139472961\n",
            "epoch 3- loss: 0.7905129790306091\n",
            "epoch 3- loss: 0.8422255516052246\n",
            "epoch 3- loss: 0.7704252600669861\n",
            "epoch 3- loss: 0.7818064093589783\n",
            "epoch 3- loss: 0.8871384859085083\n",
            "epoch 3- loss: 0.782004177570343\n",
            "epoch 3- loss: 0.8047785758972168\n",
            "epoch 3- loss: 0.8312999606132507\n",
            "epoch 3- loss: 0.7281315922737122\n",
            "epoch 3- loss: 0.7828102111816406\n",
            "epoch 3- loss: 0.7768434882164001\n",
            "epoch 3- loss: 0.7481347322463989\n",
            "epoch 3- loss: 0.7364648580551147\n",
            "epoch 3- loss: 0.7031259536743164\n",
            "epoch 3- loss: 0.8244256377220154\n",
            "epoch 3- loss: 0.697899580001831\n",
            "epoch 3- loss: 0.7831695079803467\n",
            "epoch 3- loss: 0.7495083212852478\n",
            "epoch 3- loss: 0.7782544493675232\n",
            "epoch 3- loss: 0.7316759824752808\n",
            "epoch 3- loss: 0.7804961204528809\n",
            "epoch 3- loss: 0.7434571981430054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:51<07:06, 15.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3- loss: 0.7530217170715332\n",
            "3th epoch end. Avg loss: 0.7883872968701128\n",
            "epoch 4- loss: 0.7070959806442261\n",
            "epoch 4- loss: 0.7131262421607971\n",
            "epoch 4- loss: 0.7795122265815735\n",
            "epoch 4- loss: 0.6976641416549683\n",
            "epoch 4- loss: 0.7107453346252441\n",
            "epoch 4- loss: 0.715610921382904\n",
            "epoch 4- loss: 0.8611559867858887\n",
            "epoch 4- loss: 0.8266251683235168\n",
            "epoch 4- loss: 0.7299543619155884\n",
            "epoch 4- loss: 0.7827078700065613\n",
            "epoch 4- loss: 0.7823619246482849\n",
            "epoch 4- loss: 0.762150228023529\n",
            "epoch 4- loss: 0.6916908025741577\n",
            "epoch 4- loss: 0.7340007424354553\n",
            "epoch 4- loss: 0.6460446715354919\n",
            "epoch 4- loss: 0.6736921072006226\n",
            "epoch 4- loss: 0.7227196097373962\n",
            "epoch 4- loss: 0.7675772309303284\n",
            "epoch 4- loss: 0.7277911305427551\n",
            "epoch 4- loss: 0.6997172832489014\n",
            "epoch 4- loss: 0.79668128490448\n",
            "epoch 4- loss: 0.7232690453529358\n",
            "epoch 4- loss: 0.7337512969970703\n",
            "epoch 4- loss: 0.7992051839828491\n",
            "epoch 4- loss: 0.8684308528900146\n",
            "epoch 4- loss: 0.757362961769104\n",
            "epoch 4- loss: 0.6825699210166931\n",
            "epoch 4- loss: 0.6889463067054749\n",
            "epoch 4- loss: 0.7088524699211121\n",
            "epoch 4- loss: 0.7079631686210632\n",
            "epoch 4- loss: 0.6983106732368469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [01:04<06:22, 14.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4- loss: 0.7105065584182739\n",
            "4th epoch end. Avg loss: 0.7574085557041839\n",
            "epoch 5- loss: 0.7601500749588013\n",
            "epoch 5- loss: 0.747754693031311\n",
            "epoch 5- loss: 0.788899838924408\n",
            "epoch 5- loss: 0.7063006162643433\n",
            "epoch 5- loss: 0.724290668964386\n",
            "epoch 5- loss: 0.8026777505874634\n",
            "epoch 5- loss: 0.719792366027832\n",
            "epoch 5- loss: 0.8455401659011841\n",
            "epoch 5- loss: 0.8038150668144226\n",
            "epoch 5- loss: 0.8285909295082092\n",
            "epoch 5- loss: 0.6802284717559814\n",
            "epoch 5- loss: 0.7176029086112976\n",
            "epoch 5- loss: 0.6803160309791565\n",
            "epoch 5- loss: 0.7368060350418091\n",
            "epoch 5- loss: 0.7494210004806519\n",
            "epoch 5- loss: 0.7551848888397217\n",
            "epoch 5- loss: 0.6915149092674255\n",
            "epoch 5- loss: 0.7643218636512756\n",
            "epoch 5- loss: 0.7175635695457458\n",
            "epoch 5- loss: 0.7457119226455688\n",
            "epoch 5- loss: 0.7626882791519165\n",
            "epoch 5- loss: 0.7528018951416016\n",
            "epoch 5- loss: 0.7147287130355835\n",
            "epoch 5- loss: 1.0688910484313965\n",
            "epoch 5- loss: 0.7493776679039001\n",
            "epoch 5- loss: 0.8142896294593811\n",
            "epoch 5- loss: 0.6773440837860107\n",
            "epoch 5- loss: 0.7928395867347717\n",
            "epoch 5- loss: 0.767022967338562\n",
            "epoch 5- loss: 0.7390649318695068\n",
            "epoch 5- loss: 0.7942776679992676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [01:17<05:52, 14.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5- loss: 0.7494186758995056\n",
            "5th epoch end. Avg loss: 0.7474013370827745\n",
            "epoch 6- loss: 0.7862500548362732\n",
            "epoch 6- loss: 0.7118969559669495\n",
            "epoch 6- loss: 0.7500959634780884\n",
            "epoch 6- loss: 0.7793929576873779\n",
            "epoch 6- loss: 0.7764898538589478\n",
            "epoch 6- loss: 0.7546265125274658\n",
            "epoch 6- loss: 0.7696437835693359\n",
            "epoch 6- loss: 0.7683655619621277\n",
            "epoch 6- loss: 0.7646577954292297\n",
            "epoch 6- loss: 0.6984355449676514\n",
            "epoch 6- loss: 0.7103573083877563\n",
            "epoch 6- loss: 0.7214754819869995\n",
            "epoch 6- loss: 0.7862439751625061\n",
            "epoch 6- loss: 0.6945375204086304\n",
            "epoch 6- loss: 0.7856948971748352\n",
            "epoch 6- loss: 0.7351394295692444\n",
            "epoch 6- loss: 0.7221782207489014\n",
            "epoch 6- loss: 0.680417001247406\n",
            "epoch 6- loss: 0.7892569303512573\n",
            "epoch 6- loss: 0.7685316205024719\n",
            "epoch 6- loss: 0.6860811114311218\n",
            "epoch 6- loss: 0.7931084036827087\n",
            "epoch 6- loss: 0.7381157875061035\n",
            "epoch 6- loss: 0.7205492258071899\n",
            "epoch 6- loss: 0.7413592338562012\n",
            "epoch 6- loss: 0.6313061118125916\n",
            "epoch 6- loss: 0.6481010913848877\n",
            "epoch 6- loss: 0.7364434003829956\n",
            "epoch 6- loss: 0.7037433385848999\n",
            "epoch 6- loss: 0.7114976048469543\n",
            "epoch 6- loss: 0.7683318853378296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [01:30<05:29, 13.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6- loss: 0.6928310990333557\n",
            "6th epoch end. Avg loss: 0.7392893995339878\n",
            "epoch 7- loss: 0.6954134106636047\n",
            "epoch 7- loss: 0.7487210631370544\n",
            "epoch 7- loss: 0.7506810426712036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 定义计算准确率函数\n",
        "def compute_accuracy(model, test_dataset):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataset:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += 1\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# 计算准确率\n",
        "accuracy = compute_accuracy(net, char_dataloader)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "HpDKgA6q4ltX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建一个与原始模型相同结构的模型实例\n",
        "net = models.resnet18(num_classes=40)\n",
        "\n",
        "# 加载保存的权重\n",
        "checkpoint = torch.load(save_path)\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# 设置模型为评估模式\n",
        "net.eval()\n",
        "\n",
        "# 准备待推理的图像\n",
        "image_path = './Single_char_image_generator/output/img_0000014.jpg'\n",
        "image = Image.open(image_path)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "input_image = transform(image).unsqueeze(0)\n",
        "\n",
        "# 使用模型进行推理\n",
        "with torch.no_grad():\n",
        "    outputs = net(input_image)\n",
        "\n",
        "# 获取预测结果\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "prediction = predicted.item()\n",
        "\n",
        "# 输出预测结果\n",
        "print('Prediction:', prediction)\n"
      ],
      "metadata": {
        "id": "dNDRx3tCy_lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义类别标签映射\n",
        "class_labels = ['肉','古','幼','酥','成','傢','婦','汎','貨','理','男','大','老','樹','民','鴻','禾','髮','酒','麗','鹽','容','由','寵','中','速','食','汽','子','院','批','洗','素','我','快','雞','出','動','品','活']  # 替换为你的实际类别标签\n",
        "\n",
        "# 获取预测结果\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "prediction = predicted.item()\n",
        "\n",
        "# 根据类别索引获取类别标签\n",
        "predicted_label = class_labels[prediction-1]\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "# 输出预测结果\n",
        "print('Prediction:', predicted_label)\n"
      ],
      "metadata": {
        "id": "iDUFPBld2spc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_aoxEUFW73L-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}